# AutoPaperClassifier

## Document Intelligence: BERT-Powered PDF Classifier with FastAPI

This project demonstrates how to build a BERT-based document classification pipeline that processes research papers in PDF format and predicts their relevance to a specific category â€” such as whether a paper shares a dataset. It integrates Natural Language Processing with modern backend APIs to make the model accessible via a simple HTTP interface.

---

## ğŸ” Use Case

Designed for scenarios where you want to:
- Automatically classify scientific papers or business documents.
- Identify papers that share open datasets for research aggregation.
- Build intelligent search pipelines over large collections of academic PDFs.

---

## ğŸ§  Whatâ€™s Inside?

### 1. Transformer-based Text Classifier
- Uses `bert-base-uncased` from Hugging Face Transformers.
- Fine-tuned for binary/multiclass classification on parsed PDF text.

### 2. PDF Parsing and Preprocessing
- Extracts text from PDF files using `PyMuPDF` (via `fitz`).
- Prepares inputs compatible with BERT tokenization.

### 3. FastAPI Backend
- Exposes a `/predict/` endpoint for uploading PDF files.
- Returns the modelâ€™s prediction in a simple JSON response.

---

ğŸ“¦ AutoPaperClassifier/
AutoPaperClassifier/
â”‚
â”œâ”€â”€ api/                                  # ğŸ“¡ FastAPI-based API server
â”‚   â”œâ”€â”€ app.py                            # ğŸ”¥ FastAPI app with /predict endpoint
â”‚   â”œâ”€â”€ inference.py                      # ğŸ” Model loading + prediction pipeline
â”‚   â””â”€â”€ model/
â”‚       â”œâ”€â”€ __init__.py                   # ğŸ§© Makes 'model' a package
â”‚       â””â”€â”€ bert_classifier.py            # ğŸ¤– BERT-based classifier definition
â”‚
â”œâ”€â”€ saved_model/                          # ğŸ’¾ Stored model and encoders
â”‚   â”œâ”€â”€ model.pt                          # ğŸ§  Trained PyTorch model weights
â”‚   â””â”€â”€ label_encoder.joblib              # ğŸ·ï¸ Scikit-learn LabelEncoder
â”‚
â”œâ”€â”€ experiment_01_document_classifier.ipynb  # ğŸ““ Notebook: training, evaluation, saving model
â”‚
â”œâ”€â”€ requirements.txt                      # ğŸ“¦ Python dependencies (transformers, torch, fastapi, etc.)
â”‚
â”œâ”€â”€ README.md                             # ğŸ“– Project description and usage
â”‚
â””â”€â”€ .gitignore                            # ğŸš« Files and folders to ignore in version control



## ğŸš€ Getting Started

### 1. Clone the repository
    ```bash
    git clone https://github.com/yourusername/document-intelligence-api.git
    cd document-intelligence-api


### 2. Set up virtual environment
    ```bash
    python -m venv ml-env
    source ml-env/bin/activate
    pip install -r requirements.txt
### 3. Run the FastAPI app
    ```bash
    uvicorn api.app:app --reload
    
## ğŸ§© Future Extensions
###Support multilingual models (e.g. xlm-roberta).

###Add PDF metadata + citation extraction.

###Train on larger corpora using scientific datasets like S2ORC.

###Deploy as a microservice in a cloud or containerized environment.

## ğŸ“„ License
This project is licensed under the MIT License.

## ğŸ’¡ Inspiration
Originally built as part of an end-to-end GenAI workflow to explore intelligent document understanding using transformer models and scalable APIs.

Thankyou :)


